{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "165db964-7520-4e96-a5fb-9ed17049797d",
   "metadata": {},
   "source": [
    "Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4123708-b9eb-475f-94a1-548633e23f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaa13c5-d54f-4c97-96c7-2eb943b80c70",
   "metadata": {},
   "source": [
    "Fetching dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9af0303-4ea0-4931-9e67-3f4179524a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam.csv\", encoding = \"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1acd7b-af01-4431-9492-2ddc4d20ce04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cad320-d608-4730-8216-656e296f968b",
   "metadata": {},
   "source": [
    " Making data shine: fewer columns, clearer names (like lipstick on a girl - enhances what's already beautiful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5213390-1221-409f-87dc-05812d0e832c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [df.columns[2], df.columns[3], df.columns[4]], inplace = True)\n",
    "df.rename(columns = {\"v1\" : \"label\", \"v2\" : \"text\"}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4770df42-e853-48c9-a68e-8abd756e7ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                               text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2fcbf1-00fa-47c9-8050-1f23bd64fce2",
   "metadata": {},
   "source": [
    "Replacing \"ham\" and \"spam\" with numbers... because computers can only understand pizza with or without pineapple (clearly inferior taste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cdfffe9-6b1b-43b1-927f-ed2f0353c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df[\"label\"] = encoder.fit_transform(df[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a8d973-7d38-4487-bb08-422b43148d29",
   "metadata": {},
   "source": [
    "Hsekar Data cleaning Services: Cleaning Up Missing Socks & Copycat Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27983db1-69a5-4931-bba6-765c8d3fe46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label    0\n",
      "text     0\n",
      "dtype: int64 403\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum(), df.duplicated().sum()) # Checking data health: missing values & sneaky duplicates\n",
    "if df.duplicated().sum() != 0:\n",
    "    df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d869628a-7ff6-4bfd-93da-d7abb17da869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69106b1e-4571-4de1-8185-52b5729cdfc3",
   "metadata": {},
   "source": [
    "**Text Boot Camp:** \n",
    "  This function gets your text data in top shape for analysis. \n",
    "  We'll ditch unnecessary words and shrink others down, \n",
    "  making everything cleaner and easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d70ef05-5ff8-4b7e-a00b-79b759b4ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def text_preprocess(text):\n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    text = text.lower()    \n",
    "    text = nltk.word_tokenize(text)\n",
    "    li = [x for x in text if x.isalpha() == True and (x not in stopwords.words(\"english\")) and x not in string.punctuation] # Removing useless symbols and hardy grammar\n",
    "    text = li[:]\n",
    "    li.clear()\n",
    "    li = [stemmer.stem(x) for x in text]\n",
    "    return \" \".join(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5653728-9401-43fb-97ed-c3b67a71b2b8",
   "metadata": {},
   "source": [
    "Testing the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5af466d-4c80-4ca7-9411-7f82c2a6430f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wait dear cute madam garu'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocess(\"I am waiting for you my dear cute madam garu...! \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410b8b60-141b-4e2a-8d33-a1f76aca4113",
   "metadata": {},
   "source": [
    "Text Boot Camp in action! Transforming data for smoother analysis (computers love a concise diet)\n",
    "for the brainless people like me computers love a concise diet ==> reducing the size of the text by removing unnecessary things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfa25578-9371-43f7-9aa0-852789f8119d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rakes\\AppData\\Local\\Temp\\ipykernel_1696\\1535179038.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_transformed\"] = df[\"text\"].apply(text_preprocess)\n"
     ]
    }
   ],
   "source": [
    "df[\"text_transformed\"] = df[\"text\"].apply(text_preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8686d57a-7700-4bf5-9e00-cc1999cdf5ad",
   "metadata": {},
   "source": [
    " Let's peek at our shiny new column, \"text_transformed\"! (All that hard work paid off!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f9a492d-d7db-4e00-8063-43293fcaba77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go jurong point crazi avail bugi n great world...\n",
      "1                                   ok lar joke wif u oni\n",
      "2       free entri wkli comp win fa cup final tkt may ...\n",
      "3                     u dun say earli hor u c alreadi say\n",
      "4                    nah think goe usf live around though\n",
      "                              ...                        \n",
      "5567    time tri contact u pound prize claim easi call...\n",
      "5568                                b go esplanad fr home\n",
      "5569                                    piti mood suggest\n",
      "5570    guy bitch act like interest buy someth els nex...\n",
      "5571                                       rofl true name\n",
      "Name: text_transformed, Length: 5169, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df[\"text_transformed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa14ad50-b5d5-4964-9eb3-438c52dff4c5",
   "metadata": {},
   "source": [
    "Text to features:  Unleashing the secret language of our data (machines love numbers, not words!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9051c438-df0f-4053-8d6f-ff8b35b545b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features = 3000)\n",
    "X = vectorizer.fit_transform(df[\"text_transformed\"]).toarray()\n",
    "y = df[\"label\"].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d944fb-f3af-434c-a6ca-6ffa862f1a4d",
   "metadata": {},
   "source": [
    "Dividing the data: Training set for the A-team, Testing set for the B-team (both ready to learn!) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ccff636-0e17-4c31-9a80-35f1336d5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1cf5e5-e1c5-450e-8b81-601956e5f230",
   "metadata": {},
   "source": [
    "Training the model and Unleashing Sherlock (our text classifier): Time to see how well it detects spam by knowing it's accuracy\n",
    "and precision score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3fc6b30-8e84-4501-a3a5-0c86d1c18f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9729206963249516\n",
      "0.9915966386554622\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_predicted = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_predicted))\n",
    "print(precision_score(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47296860-d471-491b-8d28-7ccd35b59233",
   "metadata": {},
   "source": [
    "**Mic Drop Moment!**  Our model achieved a whopping 97.2% accuracy and 99.2% precision!  :-)\n",
    "\n",
    "Looks like spam can't hide from us anymore. Time to celebrate (with responsibly-sized cupcakes)! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d54d07a8-a63d-4a88-9a39-e873c571f036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(msg):\n",
    "    msg = text_preprocess(msg)\n",
    "    msg_vec = vectorizer.transform([msg])\n",
    "\n",
    "    if model.predict(msg_vec) == 1:\n",
    "        print(\"It's a SPAM\")\n",
    "    else:\n",
    "        print(\"It's not a SPAM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "07945964-1c99-45e1-92fd-95e4c44e2049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's not a SPAM\n"
     ]
    }
   ],
   "source": [
    "msg1 = \"\"\"\n",
    "    How are you my dear cute madam garu...?\n",
    "    I have a lot of love transactions that are in queue(pending).\n",
    "    Will you please help me to complete that love transactions madam garu...?\n",
    "\"\"\"\n",
    "predict(msg1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eea4a3f3-cb2a-482f-95b9-2acf3d86c7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a SPAM\n"
     ]
    }
   ],
   "source": [
    "msg2 = \"\"\"\n",
    "  Had your mobile 11 months or more? U R entitled to Update to the latest colour mobiles \n",
    "  with camera for Free! Call The Mobile Update Co FREE on 08002986030\n",
    "\"\"\"\n",
    "predict(msg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4d8fe9e-3250-4464-bab2-476332164705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a SPAM\n"
     ]
    }
   ],
   "source": [
    "msg3 = \"\"\"\n",
    "    Congratulations! Your credit score entitles you to a no-interest Visa credit card. Click here to claim: \"https://www.rakeshspams.com\"\n",
    "\"\"\"\n",
    "predict(msg3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a17498-ecf5-4788-b308-27861eec1994",
   "metadata": {},
   "source": [
    "I need to save this model because I'm lazy enough to not repeat these all steps again...! :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "768ffa61-7de5-4d0d-b85d-3cc4d3b90a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a50a7ba-e6c0-469d-a7f3-180c9dbe298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"spam-classifier-model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9951cd62-0650-4950-9334-e49926533883",
   "metadata": {},
   "source": [
    "Save the vectorizer. Don't let our model get confused by fancy new words it\n",
    "didn't learn in training school! (Ensures consistent text preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "45e47cec-47f9-4823-9e12-1771e91f3cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
